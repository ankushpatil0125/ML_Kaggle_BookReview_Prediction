{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7052919,"sourceType":"datasetVersion","datasetId":4059302}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-26T13:07:52.091814Z","iopub.execute_input":"2023-11-26T13:07:52.092295Z","iopub.status.idle":"2023-11-26T13:07:52.442616Z","shell.execute_reply.started":"2023-11-26T13:07:52.092249Z","shell.execute_reply":"2023-11-26T13:07:52.441711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import preprocessed training data","metadata":{}},{"cell_type":"code","source":"path_link=\"/kaggle/input/final-preprocessed/final_preprocessed.csv\"\ndf=pd.read_csv(path_link)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:07:52.444461Z","iopub.execute_input":"2023-11-26T13:07:52.444846Z","iopub.status.idle":"2023-11-26T13:08:00.404504Z","shell.execute_reply.started":"2023-11-26T13:07:52.444821Z","shell.execute_reply":"2023-11-26T13:08:00.403693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fill na with ' '","metadata":{}},{"cell_type":"code","source":"df['review_text'].fillna('', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:08:00.405565Z","iopub.execute_input":"2023-11-26T13:08:00.405873Z","iopub.status.idle":"2023-11-26T13:08:00.519954Z","shell.execute_reply.started":"2023-11-26T13:08:00.405847Z","shell.execute_reply":"2023-11-26T13:08:00.519148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Perform Tfidf vectorization","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n\n# Fit and transform the training data\nX_train_tfidf = tfidf_vectorizer.fit_transform(df['review_text'])","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:08:00.520971Z","iopub.execute_input":"2023-11-26T13:08:00.521211Z","iopub.status.idle":"2023-11-26T13:11:41.536155Z","shell.execute_reply.started":"2023-11-26T13:08:00.521189Z","shell.execute_reply":"2023-11-26T13:11:41.535346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\n\n\n# Initialize Logistic Regression model\nlogreg = LogisticRegression(max_iter=2000)\n\n# Fit the model\nlogreg.fit(X_train_tfidf, df['rating'])","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:11:41.538209Z","iopub.execute_input":"2023-11-26T13:11:41.538521Z","iopub.status.idle":"2023-11-26T17:13:13.546064Z","shell.execute_reply.started":"2023-11-26T13:11:41.538495Z","shell.execute_reply":"2023-11-26T17:13:13.545258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:13:13.547196Z","iopub.execute_input":"2023-11-26T17:13:13.547542Z","iopub.status.idle":"2023-11-26T17:13:13.559508Z","shell.execute_reply.started":"2023-11-26T17:13:13.547516Z","shell.execute_reply":"2023-11-26T17:13:13.558591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Store train model in pickle file","metadata":{}},{"cell_type":"code","source":"import pickle\nwith open('trained_model.pkl', 'wb') as file:\n    pickle.dump(logreg, file)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:13:13.561019Z","iopub.execute_input":"2023-11-26T17:13:13.561403Z","iopub.status.idle":"2023-11-26T17:13:15.060737Z","shell.execute_reply.started":"2023-11-26T17:13:13.561370Z","shell.execute_reply":"2023-11-26T17:13:15.059725Z"},"trusted":true},"execution_count":null,"outputs":[]}]}